{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMbDra/NraFjIhsJBJfqtlk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vishnusnath447/test-google-colab/blob/main/WebPageSummerizer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bLWdBXOcc-q9",
        "outputId": "43f4fd48-ff48-4886-fbea-92a70db1268a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.41.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.31.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (4.12.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.14.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.23.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2024.6.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4) (2.5)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (4.12.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers requests beautifulsoup4"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from transformers import PegasusForConditionalGeneration, PegasusTokenizer\n",
        "\n",
        "# Function to fetch and scrape reviews from the webpage\n",
        "def scrape_reviews(url):\n",
        "    response = requests.get(url)\n",
        "    response.raise_for_status()\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "    # Adjust based on your actual HTML structure\n",
        "    reviews = []\n",
        "    review_elements = soup.find_all('p')\n",
        "    for review in review_elements:\n",
        "        reviews.append(review.get_text(strip=True))\n",
        "\n",
        "    return reviews\n",
        "\n",
        "# Function to generate suggestions based on the summaries\n",
        "def generate_suggestions(summary):\n",
        "    # Implement your suggestion generation logic here\n",
        "    # For example, extract common themes or issues from the summary\n",
        "    suggestions = \"Placeholder suggestion: Improve battery life and add dark mode.\"\n",
        "    return suggestions\n",
        "\n",
        "# Main function to scrape, summarize, and generate suggestions\n",
        "def main():\n",
        "    url = \"https://1ddd7f45-3272-4e73-8105-c15e6e7560c4-00-2twkoe64h1tyw.sisko.replit.dev/\"  # Replace with your actual webpage URL\n",
        "    reviews = scrape_reviews(url)\n",
        "\n",
        "    if not reviews:\n",
        "        print(\"No reviews found. Please check the class name and the webpage structure.\")\n",
        "        return\n",
        "\n",
        "    # Initialize the Pegasus tokenizer and model\n",
        "    model_name = \"google/pegasus-large\"\n",
        "    tokenizer = PegasusTokenizer.from_pretrained(model_name)\n",
        "    model = PegasusForConditionalGeneration.from_pretrained(model_name).cuda()  # Move model to GPU\n",
        "\n",
        "    # Summarize all reviews\n",
        "    combined_reviews = \" \".join(reviews)\n",
        "    inputs = tokenizer.encode(\"summarize: \" + combined_reviews, return_tensors=\"pt\", max_length=1024, truncation=True).cuda()  # Move input to GPU\n",
        "    summary_ids = model.generate(inputs, max_length=150, min_length=30, length_penalty=2.0, num_beams=4, early_stopping=True)\n",
        "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "\n",
        "    # Generate suggestions based on the summary\n",
        "    suggestions = generate_suggestions(summary)\n",
        "\n",
        "    # Print the combined summary and suggestions\n",
        "    print(\"Combined Summary of Reviews:\")\n",
        "    print(summary)\n",
        "    print(\"\\nCommon Suggestions:\")\n",
        "    print(suggestions)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CgWA6n80eR_s",
        "outputId": "e75ec98e-04b8-4cfd-b9c7-480ffc338023"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of PegasusForConditionalGeneration were not initialized from the model checkpoint at google/pegasus-large and are newly initialized: ['model.decoder.embed_positions.weight', 'model.encoder.embed_positions.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Combined Summary of Reviews:\n",
            "The interface is intuitive, but I really wish there was a dark mode option for better night viewing. Love the app's functionality, but a dark mode and calendar integration would make it perfect!\n",
            "\n",
            "Common Suggestions:\n",
            "Placeholder suggestion: Improve battery life and add dark mode.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from transformers import pipeline\n",
        "\n",
        "# Function to fetch and scrape reviews from the webpage\n",
        "def scrape_reviews(url):\n",
        "    response = requests.get(url)\n",
        "    response.raise_for_status()\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "    # Update the class name based on your webpage structure\n",
        "    review_elements = soup.find_all(class_='reviews')\n",
        "\n",
        "    reviews = [review.get_text(strip=True) for review in review_elements]\n",
        "    return reviews\n",
        "\n",
        "# Function to summarize the reviews\n",
        "def summarize_reviews(reviews, summarizer):\n",
        "    summaries = [summarizer(review, max_length=150, min_length=30, do_sample=False)[0]['summary_text'] for review in reviews]\n",
        "    return summaries\n",
        "\n",
        "# Function to generate suggestions based on the summaries\n",
        "def generate_suggestions(summaries, generator):\n",
        "    combined_summaries = \" \".join(summaries)\n",
        "    prompt = f\"Based on the following reviews, provide suggestions for improvement: {combined_summaries}\"\n",
        "\n",
        "    suggestions = generator(prompt, max_length=150, num_return_sequences=1)\n",
        "    return suggestions[0]['generated_text']\n",
        "\n",
        "# Main function to scrape, summarize, and generate suggestions\n",
        "def main():\n",
        "    url = \"https://1ddd7f45-3272-4e73-8105-c15e6e7560c4-00-2twkoe64h1tyw.sisko.replit.dev/\"  # Replace with your actual webpage URL\n",
        "    reviews = scrape_reviews(url)\n",
        "\n",
        "    if not reviews:\n",
        "        print(\"No reviews found. Please check the class name and the webpage structure.\")\n",
        "        return\n",
        "\n",
        "    # Initialize the summarizer\n",
        "    summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
        "\n",
        "    # Summarize the reviews\n",
        "    summaries = summarize_reviews(reviews, summarizer)\n",
        "\n",
        "    # Initialize the text generator\n",
        "    generator = pipeline(\"text-generation\", model=\"facebook/bart-large-cnn\")\n",
        "\n",
        "    # Generate suggestions based on summaries\n",
        "    suggestions = generate_suggestions(summaries, generator)\n",
        "\n",
        "    # Print summaries and suggestions\n",
        "    print(\"Summaries:\")\n",
        "    for i, summary in enumerate(summaries, 1):\n",
        "        print(f\"Review {i}: {summary}\\n\")\n",
        "\n",
        "    print(\"Suggestions:\")\n",
        "    print(suggestions)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vtqnM5SWenS6",
        "outputId": "0774ccd3-39f7-409c-813a-bb13ff406fa9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summaries:\n",
            "Review 1: The battery drain is unreal! My phone barely lasts a day. Wish there was a battery saver mode. It would be amazing if you could integrate a calendar sync feature. The interface is intuitive, but I really wish there was an option for better night viewing.\n",
            "\n",
            "Suggestions:\n",
            "Based on the following reviews, provide suggestions for improvement: The battery drain is unreal! My phone barely lasts a day. Wish there was a battery saver mode. It would be amazing if you could integrate a calendar sync feature. The interface is intuitive, but I really wish there was an option for better night viewing. over over onete one over their overte one is one over l over over over just one over one over Their overte last with over overge over still overge just one isara one over still one over with one over my overge one over is onease over stillge over just overge which with their their over their one over\"ge over over a overge like overge a whichge overge between with\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from transformers import T5ForConditionalGeneration, T5Tokenizer, pipeline\n",
        "\n",
        "# Function to fetch and scrape reviews from the webpage\n",
        "def scrape_reviews(url):\n",
        "    response = requests.get(url)\n",
        "    response.raise_for_status()\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "    # Update the class name based on your webpage structure\n",
        "    # review_elements = soup.find_all(class_='reviews')\n",
        "\n",
        "    # reviews = [review.get_text(strip=True) for review in review_elements]\n",
        "    # return reviews\n",
        "    reviews = []\n",
        "    review_elements = soup.find_all('p')\n",
        "    for review in review_elements:\n",
        "        reviews.append(review.get_text(strip=True))\n",
        "\n",
        "    return reviews\n",
        "\n",
        "# Function to summarize the reviews\n",
        "def summarize_reviews(reviews, summarizer):\n",
        "    summaries = [summarizer(review, max_length=150, min_length=30, do_sample=False)[0]['summary_text'] for review in reviews]\n",
        "    return summaries\n",
        "\n",
        "# Function to generate suggestions based on the summaries\n",
        "def generate_suggestions(summaries, generator, tokenizer):\n",
        "    combined_summaries = \" \".join(summaries)\n",
        "    prompt = f\"Based on the following reviews, provide suggestions for improvement: {combined_summaries}\"\n",
        "\n",
        "    inputs = tokenizer.encode(\"summarize: \" + prompt, return_tensors=\"pt\", max_length=512, truncation=True)\n",
        "    outputs = generator.generate(inputs, max_length=150, num_beams=5, early_stopping=True)\n",
        "    suggestions = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "    return suggestions\n",
        "\n",
        "# Main function to scrape, summarize, and generate suggestions\n",
        "def main():\n",
        "    url = \"https://1ddd7f45-3272-4e73-8105-c15e6e7560c4-00-2twkoe64h1tyw.sisko.replit.dev/\"  # Replace with your actual webpage URL\n",
        "    reviews = scrape_reviews(url)\n",
        "\n",
        "    if not reviews:\n",
        "        print(\"No reviews found. Please check the class name and the webpage structure.\")\n",
        "        return\n",
        "\n",
        "    # Initialize the summarizer\n",
        "    summarizer = pipeline(\"summarization\", model=\"t5-large\")\n",
        "\n",
        "    # Summarize the reviews\n",
        "    summaries = summarize_reviews(reviews, summarizer)\n",
        "\n",
        "    # Initialize the T5 model for text generation\n",
        "    model_name = \"t5-large\"\n",
        "    generator = T5ForConditionalGeneration.from_pretrained(model_name)\n",
        "    tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
        "\n",
        "    # Generate suggestions based on summaries\n",
        "    suggestions = generate_suggestions(summaries, generator, tokenizer)\n",
        "\n",
        "    # Print summaries and suggestions\n",
        "    print(\"Summaries:\")\n",
        "    for i, summary in enumerate(summaries, 1):\n",
        "        print(f\"Review {i}: {summary}\\n\")\n",
        "\n",
        "    print(\"Suggestions:\")\n",
        "    print(suggestions)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gU6IXU_Nhw3F",
        "outputId": "98ba987c-ca6f-4369-ef34-2285b3d04aab"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "Your max_length is set to 150, but your input_length is only 27. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=13)\n",
            "Your max_length is set to 150, but your input_length is only 20. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=10)\n",
            "Your max_length is set to 150, but your input_length is only 28. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=14)\n",
            "Your max_length is set to 150, but your input_length is only 24. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=12)\n",
            "Your max_length is set to 150, but your input_length is only 26. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=13)\n",
            "Your max_length is set to 150, but your input_length is only 23. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=11)\n",
            "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summaries:\n",
            "Review 1: battery drain is unreal! my phone barely lasts a day . love the features of this app, but the battery drain .\n",
            "\n",
            "Review 2: great app concept, but the constant background refresh kills my battery . please optimize the background refresh rate . i'm using a nexus 6 tablet and it's killing my battery!\n",
            "\n",
            "Review 3: this app is awesome, but the battery life suffers after recent updates . wish there was a battery saver mode, if there was one .\n",
            "\n",
            "Review 4: the interface is intuitive, but i really wish there was a dark mode option for better night viewing . it's a shame there isn't a darker mode option, as it would have been more useful at night .\n",
            "\n",
            "Review 5: calendar sync feature would be great . i'm using it on my iphone 6s plus ipad mini . would be awesome if you could integrate it with google calendar.\n",
            "\n",
            "Review 6: a dark mode and calendar integration would make it perfect . the app has a lot of great features, but it could use a little more polish .\n",
            "\n",
            "Suggestions:\n",
            "based on the following reviews, provide suggestions for improvement: battery drain is unreal! my phone barely lasts a day. a dark mode and calendar integration would be great.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from transformers import T5ForConditionalGeneration, T5Tokenizer, pipeline\n",
        "\n",
        "# Function to fetch and scrape reviews from the webpage\n",
        "def scrape_reviews(url):\n",
        "    response = requests.get(url)\n",
        "    response.raise_for_status()\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "    # Adjust based on your actual HTML structure\n",
        "    reviews = []\n",
        "    review_elements = soup.find_all('p')\n",
        "    for review in review_elements:\n",
        "        reviews.append(review.get_text(strip=True))\n",
        "\n",
        "    return reviews\n",
        "\n",
        "# Function to summarize the reviews\n",
        "def summarize_reviews(reviews, summarizer):\n",
        "    combined_reviews = \" \".join(reviews)\n",
        "    summary = summarizer(combined_reviews, max_length=150, min_length=30, do_sample=False)\n",
        "    return summary[0]['summary_text']\n",
        "\n",
        "# Function to generate suggestions based on the summaries\n",
        "def generate_suggestions(summary, generator, tokenizer):\n",
        "    prompt = f\"Based on the following reviews, provide suggestions for improvement: {summary}\"\n",
        "\n",
        "    inputs = tokenizer.encode(prompt, return_tensors=\"pt\", max_length=512, truncation=True)\n",
        "    outputs = generator.generate(inputs, max_length=150, num_beams=5, early_stopping=True)\n",
        "    suggestions = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "    return suggestions\n",
        "\n",
        "# Main function to scrape, summarize, and generate suggestions\n",
        "def main():\n",
        "    url = \"https://1ddd7f45-3272-4e73-8105-c15e6e7560c4-00-2twkoe64h1tyw.sisko.replit.dev/\"  # Replace with your actual webpage URL\n",
        "    reviews = scrape_reviews(url)\n",
        "\n",
        "    if not reviews:\n",
        "        print(\"No reviews found. Please check the class name and the webpage structure.\")\n",
        "        return\n",
        "\n",
        "    # Initialize the summarizer\n",
        "    summarizer = pipeline(\"summarization\", model=\"t5-large\")\n",
        "\n",
        "    # Summarize all reviews\n",
        "    summary = summarize_reviews(reviews, summarizer)\n",
        "\n",
        "    # Initialize the T5 model for text generation\n",
        "    model_name = \"t5-large\"\n",
        "    generator = T5ForConditionalGeneration.from_pretrained(model_name)\n",
        "    tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
        "\n",
        "    # Generate suggestions based on the summary\n",
        "    suggestions = generate_suggestions(summary, generator, tokenizer)\n",
        "\n",
        "    # Print the combined summary and suggestions\n",
        "    print(\"Combined Summary of Reviews:\")\n",
        "    print(summary)\n",
        "    print(\"\\nCommon Suggestions:\")\n",
        "    print(suggestions)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pT_GSE59hEc8",
        "outputId": "3c176d5c-b42b-40b5-ad7d-58260f59b06b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 150, but your input_length is only 133. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=66)\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Combined Summary of Reviews:\n",
            "this app is awesome, but the battery life suffers after recent updates. wish there was a battery saver mode. the interface is intuitive, but a dark mode option for better night viewing would be perfect.\n",
            "\n",
            "Common Suggestions:\n",
            "app is awesome, but the battery life suffers after recent updates. but the battery life suffers after recent updates. awesome, but the battery life suffers after recent updates. awesome, but the battery life suffers after recent updates. Based on the following reviews, provide suggestions for improvement: provide suggestions: provide suggestions for provide suggestions for improvement: the and and............\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from transformers import T5ForConditionalGeneration, T5Tokenizer, pipeline\n",
        "\n",
        "# Function to fetch and scrape reviews from the webpage\n",
        "def scrape_reviews(url):\n",
        "    response = requests.get(url)\n",
        "    response.raise_for_status()\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "    # Adjust based on your actual HTML structure\n",
        "    reviews = []\n",
        "    review_elements = soup.find_all('p')\n",
        "    for review in review_elements:\n",
        "        reviews.append(review.get_text(strip=True))\n",
        "\n",
        "    return reviews\n",
        "\n",
        "# Function to summarize the reviews\n",
        "def summarize_reviews(reviews, summarizer):\n",
        "    combined_reviews = \" \".join(reviews)\n",
        "    input_length = len(combined_reviews)\n",
        "    max_length = min(input_length // 2, 150)  # Adjust max_length dynamically\n",
        "    summary = summarizer(combined_reviews, max_length=max_length, min_length=20, do_sample=False)\n",
        "    return summary[0]['summary_text']\n",
        "\n",
        "# Function to generate suggestions based on the summaries\n",
        "def generate_suggestions(summary, generator, tokenizer):\n",
        "    prompt = f\"Based on the following reviews, provide suggestions for improvement: {summary}\"\n",
        "\n",
        "    inputs = tokenizer.encode(prompt, return_tensors=\"pt\", max_length=512, truncation=True)\n",
        "    outputs = generator.generate(inputs.cuda(), max_length=150, num_beams=5, early_stopping=True)\n",
        "    suggestions = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "    return suggestions\n",
        "\n",
        "# Main function to scrape, summarize, and generate suggestions\n",
        "def main():\n",
        "    url = \"https://1ddd7f45-3272-4e73-8105-c15e6e7560c4-00-2twkoe64h1tyw.sisko.replit.dev/\"  # Replace with your actual webpage URL\n",
        "    reviews = scrape_reviews(url)\n",
        "\n",
        "    if not reviews:\n",
        "        print(\"No reviews found. Please check the class name and the webpage structure.\")\n",
        "        return\n",
        "\n",
        "    # Initialize the summarizer\n",
        "    summarizer = pipeline(\"summarization\", model=\"t5-large\", device=0)  # Utilize GPU explicitly\n",
        "\n",
        "    # Summarize all reviews\n",
        "    summary = summarize_reviews(reviews, summarizer)\n",
        "\n",
        "    # Initialize the T5 model for text generation\n",
        "    model_name = \"t5-large\"\n",
        "    generator = T5ForConditionalGeneration.from_pretrained(model_name).cuda()  # Move model to GPU\n",
        "    tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
        "\n",
        "    # Generate suggestions based on the summary\n",
        "    suggestions = generate_suggestions(summary, generator, tokenizer)\n",
        "\n",
        "    # Print the combined summary and suggestions\n",
        "    print(\"Combined Summary of Reviews:\")\n",
        "    print(summary)\n",
        "    print(\"\\nCommon Suggestions:\")\n",
        "    print(suggestions)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OxKqIesjkCkR",
        "outputId": "a3d31384-d058-43d8-c959-dcd2fe1f54a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 150, but your input_length is only 133. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=66)\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Combined Summary of Reviews:\n",
            "this app is awesome, but the battery life suffers after recent updates. wish there was a battery saver mode. the interface is intuitive, but a dark mode option for better night viewing would be perfect.\n",
            "\n",
            "Common Suggestions:\n",
            "app is awesome, but the battery life suffers after recent updates. but the battery life suffers after recent updates. awesome, but the battery life suffers after recent updates. awesome, but the battery life suffers after recent updates. Based on the following reviews, provide suggestions for improvement: provide suggestions: provide suggestions for provide suggestions for improvement: the and and............\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vT1c0zFZn_bW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}